{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "dataset = 'Yelp'\n",
    "stage='item'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'input/caption/{dataset}_caption.json', 'r') as file:\n",
    "    name = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"Based on the store name and your general knowledge, infer the key characteristics of the store. Include details such as its type (e.g., restaurant, mall, etc.), potential offerings or services, and target audience. Ensure the response is concise and informative.\n",
    "Example:\n",
    "Store Name: Bar-B-Cutie\n",
    "Response:\n",
    "Type: Restaurant (Barbecue-focused)\n",
    "Offerings: Likely specializes in barbecue dishes such as smoked meats, ribs, and sides. May also serve casual American comfort food.\n",
    "Target Audience: Barbecue enthusiasts, families, or individuals seeking a casual dining experience.\n",
    "Now, analyze the following store name:\n",
    "Store Name: {}\n",
    "Response:\n",
    "\"\"\"\n",
    "\n",
    "data_list = []\n",
    "file_count = 1\n",
    "\n",
    "for id, caption in tqdm(name.items()):\n",
    "    data_entry = {\n",
    "        \"custom_id\": str(id),\n",
    "        \"method\": \"POST\",\n",
    "        \"url\": \"/v1/chat/completions\",\n",
    "        \"body\": {\n",
    "            \"model\": \"gpt-4o-mini\",\n",
    "            \"messages\": [\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt.format(caption)}\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "    data_list.append(data_entry)\n",
    "\n",
    "    # 每45000条数据写入一个新文件\n",
    "    if len(data_list) >= 30000:\n",
    "        with open(f'{dataset}_{stage}request_{file_count}.jsonl', 'w', encoding='utf-8') as f:\n",
    "            for entry in data_list:\n",
    "                json.dump(entry, f, ensure_ascii=False)\n",
    "                f.write('\\n')\n",
    "        file_count += 1\n",
    "        data_list = []\n",
    "\n",
    "# 写入剩余的数据\n",
    "if data_list:\n",
    "    with open(f'{dataset}_{stage}request_{file_count}.jsonl', 'w', encoding='utf-8') as f:\n",
    "        for entry in data_list:\n",
    "            json.dump(entry, f, ensure_ascii=False)\n",
    "            f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
